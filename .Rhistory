ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq,alpha = 0.05)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq, alpha = 0.2)
ggmap(sabadell) + geom_point(aes(x = fake_lon, y = fake_lat), data = test.sq, alpha = 0.1)
data$fake_lon <- data$masked_lon - runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.1)
bcn <-  get_map("Barcelona, Spain", zoom = 15)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.1)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
bcn <-  get_map("Barcelona, Spain", zoom = 14)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.4)
bcn <-  get_map("Barcelona, Spain", zoom = 13)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.4)
ggmap(bcn) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
madrid <-  get_map("Madrid, Spain", zoom = 13)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
madrid <-  get_map("Madrid, Spain", zoom = 11)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
ggmap(madrid) + geom_point(aes(x = fake_lon, y = fake_lat), data = data, alpha = 0.2)
View(data)
library(tidyverse)
library(rvest)
d <- read_html("https://www.teenvogue.com/news-politics") %>% html_nodes(.byline-contributor-link)
d <- read_html("https://www.teenvogue.com/news-politics") %>% html_nodes(".byline-contributor-link")
d
library(tidyverse)
library(sf)
# Load Data as SF Objects
data <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
data$fake_lon <- data$masked_lon + runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
points <- data %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
polys <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
polys <- st_transform(polys, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Point in polygon function
polys$pt_count <- lengths(st_intersects(polys, points))
View(polys)
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
View(income)
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
View(income)
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
income$Renta_Hogar <- as.numeric(income$Renta_Hogar)
income$Renta_Persona <- as.numeric(income$Renta_Persona)
View(polys)
?sep
income <- income %>% separate(Area, c("CUSEC", "NMUN"))
income
# Add to ploys df
ploys <- polys %>% left_join(income, by = "CUSEC")
summary(polys)
summary(ploys)
# Add to ploys df
polys <- polys %>% left_join(income, by = "CUSEC")
library(tidyverse)
library(sf)
# Load Data as SF Objects
data <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
data$fake_lon <- data$masked_lon + runif(nrow(data), 0, .025)
data$fake_lat <- data$masked_lat + runif(nrow(data), 0, .025)
points <- data %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
polys <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
polys <- st_transform(polys, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Point in polygon function
polys$pt_count <- lengths(st_intersects(polys, points))
# Collapse by community or municipality
#communities <- st_make_valid(polys) %>% group_by(NCA) %>% summarise(obs = sum(pt_count)) %>% arrange(desc(obs))
#municipalities <- st_make_valid(polys) %>% group_by(NMUN) %>% summarise(obs = sum(pt_count)) %>% arrange(desc(obs))
# Load income data
income <- read_csv("~/research/incomebybarri.csv")
income$Renta_Persona <- as.numeric(income$Renta_Persona)
income$Renta_Hogar <- as.numeric(income$Renta_Hogar)
income <- income %>% separate(Area, c("CUSEC", "NMUN"))
# Add to ploys df
polys <- polys %>% left_join(income, by = "CUSEC")
library(ggplot2)
ggplot(polys,aes(Renta_Hogar,pt_count))
ggplot(polys,aes(Renta_Hogar,pt_count)) + geom_point()
# Twitter data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets
points <- data %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
polys$tw_count <- lengths(st_intersects(polys, tweets))
summary(polys)
ggplot(polys,aes(tw_count,pt_count)) + geom_point()
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(data), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(data), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(data), 0, .025)
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN"))
districts <- districts %>% left_join(income, by = "CUSEC")
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
ggplot(districts,aes(tw_pct,bt_pct)) + geom_point()
districts$more_tweets <- districts$tw_pct - districts$bt_pct
ggplot(districts,aes(more_tweets,renta_hogar)) + geom_point()
ggplot(districts,aes(more_tweets,renta_hogar)) + geom_point() + geom_smooth()
ggplot(filter(districts, tw_count>0),aes(more_tweets,renta_hogar)) + geom_point() + geom_smooth()
filter(districts, tw_count>0),
filter(districts, tw_count>0)
filter(districts, tw_count>10)
ggplot(filter(districts, tw_count>10),aes(more_tweets,renta_hogar)) + geom_point() + geom_smooth()
View(districts)
# Collapse by community or municipality
#communities <- st_make_valid(polys) %>% group_by(NCA) %>% summarise(obs = sum(pt_count)) %>% arrange(desc(obs))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count)) %>% summarise(tw_count = sum(tw_count))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count))
View(tweets)
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
View(districts)
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
# Collapse by community or municipality
#communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise(bt_count = sum(bt_count)) %>% arrange(desc(obs))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count)) %>% summarise(tw_count = sum(tw_count))
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(bt_count = sum(bt_count))
munitweets <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise(tw_count = sum(tw_count))
municipalities <- municipalities %>% left_join(munitweets, by = "NMUN")
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
View(municipalities)
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
View(communities)
communities
communities %>% arrange(more_tweets)
municipalities %>% arrange(more_tweets)
# CSV exports
write_csv(communities, "~/research/communities.csv")
write_csv(municipalities, "~/research/municipalities.csv")
municipalities %>% arrange(desc(more_tweets)
)
# Names of all required packages that we will be using during the course
all_pkgs <- c('tidyverse', 'jtools', 'sjPlot','ggplot2','ggthemes','haven','foreign','essurvey','stargazer','knitr','prais','orcutt','fastDummies')
# Install all the packages (it may take a few minutes to install all of them)
install.packages(all_pkgs, dependencies = TRUE)
# Verify the installation worked correctly
setdiff(all_pkgs, row.names(installed.packages()))
library(essurvey)
?essurvey
library(tidyverse)
library(sf)
# Load background track data
bgtracks <- readRDS("~/research/data/exp_pro/user_locations_small_cell.rds")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Collapse by autonomous community and municipality
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
###
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
View(districts)
communities
head(districts)
summary(districts$renta_persona)
lm(districts$bt_count ~ districts$renta_persona)
lm(bt_count ~ renta_persona, data = districts)
summary(lm(bt_count ~ renta_persona, data = districts))
-1/4
summary(lm(more_tweets ~ renta_persona, data = districts))
ggplot(districts) + geom_point(aes(more_tweets,renta_persona))
summary(lm(more_tweets ~ renta_persona, data = districts %>% filter(tw_count > 0)))
summary(lm(more_tweets ~ renta_persona, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
income
ggplot(districts) + geom_point(aes(renta_persona, more_tweets))
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0)) + geom_point(aes(renta_persona, more_tweets))
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .01)) + geom_point(aes(renta_persona, more_tweets))
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_persona, more_tweets))
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_persona, more_tweets)) + geom_smooth(aes(renta_persona, more_tweets))
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_persona, more_tweets)) + geom_smooth(aes(renta_persona, more_tweets), method = 'lm')
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_hogar, more_tweets)) + geom_smooth(aes(renta_persona, more_tweets), method = 'lm')
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_hogar, more_tweets)) + geom_smooth(aes(renta_persona, more_tweets), method = 'lm')
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_persona, more_tweets)) + geom_smooth(aes(renta_persona, more_tweets), method = 'lm')
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_hogar, more_tweets)) + geom_smooth(aes(renta_hogar, more_tweets), method = 'lm')
summary(lm(more_tweets ~ renta_hogar, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
communities
communities <- communities %>% filter(NCA != "Pais Vasco")
communities
View(communities)
write_csv(communities, "ccaapopulation.csv")
communities$NCA
ccaadata <- read_csv("ccaapopincome.csv")
ccaadata <- read_csv("ccaapopincome.csv")
ccaadata <- read_csv("~/research/ccaapopincome.csv")
ccaadata <- read_csv("~/research/ccaapopincome.csv")
communities <- communities %>% left_join(ccaadata, by = "NCA")
ggplot(communities) + geom_point(aes(population, more_tweets)) + geom_smooth(aes(population, more_tweets), method = 'lm')
communities$pop_pct <- communities$population/sum(communities$population)
communities
communities$more_pop <- communities$pop_pct - communities$bt_pct
ggplot(communities) + geom_point(aes(more_pop, more_tweets)) + geom_smooth(aes(more_pop, more_tweets), method = 'lm')
ggplot(communities %>% filter(bt_count > 20)) + geom_point(aes(more_pop, more_tweets)) + geom_smooth(aes(more_pop, more_tweets), method = 'lm')
summary(lm(more_tweets ~ more_pop, data = communities %>% filter(t_count > 0)))
summary(lm(more_tweets ~ more_pop, data = communities %>% filter(bt_count > 0)))
summary(lm(more_tweets ~ more_pop, data = communities %>% filter(bt_count > 20)))
cor(communities$more_pop, communities$more_tweets)
ggplot(communities %>% filter(bt_count > 20)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
ggplot(communities %>% filter(bt_count > 0)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
summary(lm(more_tweets ~ income, data = communities %>% filter(bt_count > 20)))
summary(lm(more_pop ~ income, data = communities %>% filter(bt_count > 20)))
ggplot(communities %>% filter(bt_count > 20)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
communities
communities
municipalities
munis <- municipalities %>% filter(bt_count>5) %>% select(NMUN,bt_count)
munis
st_geometry(munis) <- NULL
View(munis)
munis %>% filter(bt_count > 50)
munis %>% filter(bt_count > 100)
bgtracks$biweek
summary(bgtracks$year)
summary(as.numeric(bgtracks$year))
table(as.numeric(bgtracks$year))
munis %>% filter(bt_count > 115)
munis %>% filter(bt_count > 105)
munis %>% filter(bt_count > 107)
munis %>% filter(bt_count > 110)
munis %>% filter(bt_count > 109)
munis %>% filter(bt_count > 108)
munis %>% filter(bt_count > 100)
#st_geometry(munis) <- NULL
munidata <- read_csv("~/research/munipopincome.csv")
munis <- munis %>% left_join(munidata, by "NMUN")
munis <- munis %>% left_join(munidata, by = "NMUN")
View(munis)
municipalities <- municipalities %>% left_join(munidata, by = "NMUN")
municipalities <- municipalities %>% left_join(munidata, by = "NMUN")
municipalities$pop_pct <- municipalities$population/sum(municipalities$population)
municipalities$more_pop <- municipalities$pop_pct - municipalities$bt_pct
municipalities
municipalities <- municipalities %>% select(-population.x,-population.y,-income.x,-income.y)
municipalities <- municipalities %>% left_join(munidata, by = "NMUN")
municipalities$pop_pct <- municipalities$population/sum(municipalities$population)
municipalities$more_pop <- municipalities$pop_pct - municipalities$bt_pct
# Muni Analysis:
cor(municipalities$more_pop, municipalities$more_tweets)
municipalities$more_pop
municipalities$more_tweets
municipalities$pop_pct
municipalities$pop_pct <- municipalities$population/sum(municipalities$population, na.rm = T)
municipalities$more_pop <- municipalities$pop_pct - municipalities$bt_pct
# Muni Analysis:
cor(municipalities$more_pop, municipalities$more_tweets)
municipalities$pop_pct
municipalities$more_pop
# Muni Analysis:
cor(municipalities$more_pop, municipalities$more_tweets, na.rm =T)
summary(lm(more_pop ~ more_tweets, data = municipalities %>% filter(bt_count > 20)))
ggplot(municipalities %>% filter(bt_count > 20)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
summary(lm(more_pop ~ more_tweets, data = municipalities %>% filter(bt_count > 0)))
ggplot(municipalities %>% filter(bt_count > 0)) + geom_point(aes(more_pop, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
municipalities$pop_pct <- municipalities$population/sum(municipalities$population, na.rm = T)
municipalities$more_pop <- municipalities$pop_pct - municipalities$bt_pct
ggplot(municipalities %>% filter(bt_count > 0)) + geom_point(aes(more_pop, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0)) + geom_point(aes(more_pop, more_tweets)) + geom_smooth(aes(more_pop, more_tweets), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
# Muni Analysis:
cor(municipalities$more_pop, municipalities$more_tweets)
# Muni Analysis:
cor(municipalities$more_pop, municipalities$more_tweets, use = "complete.obs")
ggplot(municipalities %>% filter(bt_count > 0 & more_tweets < .02 & more_tweets > -.02)) + geom_point(aes(income, more_tweets)) + geom_smooth(aes(income, more_tweets), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0 & more_tweets < .02 & more_tweets > -.02)) + geom_point(aes(income, bt_pct)) + geom_smooth(aes(income, bt_pct), method = 'lm')
View(income)
ggplot(municipalities %>% filter(bt_count > 0 & bt_pct < .01)) + geom_point(aes(income, bt_pct)) + geom_smooth(aes(income, bt_pct), method = 'lm')
summary(lm(bt_pct ~ income, data = municipalities %>% filter(bt_count > 0)))
summary(lm(bt_pct ~ income + pop_pct, data = municipalities %>% filter(bt_count > 0)))
summary(lm(income ~ pop_pct, data = municipalities %>% filter(bt_count > 0)))
summary(lm(income ~ population, data = municipalities %>% filter(bt_count > 0)))
summary(lm(bt_pct ~ income + pop_pct, data = municipalities %>% filter(bt_count > 0)))
summary(lm(bt_count ~ income + pop_pct, data = municipalities %>% filter(bt_count > 0)))
ggplot(municipalities %>% filter(bt_count > 0 & bt_pct < .01)) + geom_point(aes(income, bt_count)) + geom_smooth(aes(income, bt_count), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0)) + geom_point(aes(income, bt_count)) + geom_smooth(aes(income, bt_count), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0 & bt_count < 2500)) + geom_point(aes(income, bt_count)) + geom_smooth(aes(income, bt_count), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0 & bt_count < 1500)) + geom_point(aes(income, bt_count)) + geom_smooth(aes(income, bt_count), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0 & bt_count < 1500)) + geom_point(aes(income, population)) + geom_smooth(aes(income, population), method = 'lm')
### All three levels
ggplot() + geom_smooth(districts, aes(renta_hogar, bt_count), method = 'lm')
### All three levels
ggplot() + geom_smooth(data = districts, aes(renta_hogar, bt_count), method = 'lm')
### All three levels
ggplot() + geom_smooth(data = districts, aes(renta_hogar, bt_count), method = 'lm') + geom_smooth(data = communities, aes(income, bt_count), method = 'lm')
income
summary(lm(more_pop ~ income, data = communities %>% filter(bt_count > 20)))
summary(lm(more_tweets ~ income, data = communities %>% filter(bt_count > 20)))
# CCAA Analysis: no added value using tweets, no relationship w/ income
cor(communities$more_pop, communities$more_tweets)
# CCAA Analysis: no added value using tweets, no relationship w/ income
cor(communities$more_pop, communities$more_tweets, communities$income)
# Muni Analysis: Pop & tweets not as closely correlated, still no relation w/ income
cor(municipalities$more_pop, municipalities$more_tweets, municipalities$income, use = "complete.obs")
# Muni Analysis: Pop & tweets not as closely correlated, still no relation w/ income
cor(municipalities, use = "complete.obs")
# Muni Analysis: Pop & tweets not as closely correlated, still no relation w/ income
cor(municipalities$more_tweets, municipalities$income, use = "complete.obs")
# Muni Analysis: Pop & tweets not as closely correlated, still no relation w/ income
cor(municipalities$more_pop, municipalities$income, use = "complete.obs")
# Muni Analysis: Pop & tweets not as closely correlated, still no relation w/ income
cor(municipalities$more_pop, municipalities$more_tweets, use = "complete.obs")
population <- read_csv("~/research/popbybarri.csv")
population
population <- read_csv("~/research/popbybarri.csv")
population
View(population)
income
population <- read_csv("~/research/popbybarri.csv")
districts <- districts %>% left_join(population, by = "CUSEC")
population$CUSEC <- as.character(population$CUSEC)
districts <- districts %>% left_join(population, by = "CUSEC")
districts$population
income
population
summary(districts$population)
summary(districts$income)
summary(as.numeric(districts$income))
summary(districts$renta_hogar)
districts$pop_pct <- districts$population/sum(districts$population, na.rm = T)
districts$more_pop <- districts$pop_pct - districts$bt_pct
summary(districts$more_pop)
max(districts$more_pop)
max(districts$more_pop, na.rm = T)
# Analysis: no relationship
cor(districts$more_pop, districts$more_tweets, use = "complete.obs")
summary(lm(more_tweets ~ renta_hogar, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
summary(lm(more_pop ~ renta_hogar, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0 & more_tweets < .005)) + geom_point(aes(renta_hogar, more_pop)) + geom_smooth(aes(renta_hogar, more_pop), method = 'lm')
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0)) + geom_point(aes(renta_hogar, more_pop)) + geom_smooth(aes(renta_hogar, more_pop), method = 'lm')
ggplot(districts %>% filter(tw_count > 5 & bt_count > 5)) + geom_point(aes(renta_hogar, more_pop)) + geom_smooth(aes(renta_hogar, more_pop), method = 'lm')
ggplot(districts %>% filter(tw_count > 10 & bt_count > 10)) + geom_point(aes(renta_hogar, more_pop)) + geom_smooth(aes(renta_hogar, more_pop), method = 'lm')
ggplot(districts %>% filter(tw_count > 0 & bt_count > 0)) + geom_point(aes(renta_hogar, more_tweets)) + geom_smooth(aes(renta_hogar, more_tweets), method = 'lm')
View(districts)
summary(lm(more_tweets ~ renta_hogar, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
summary(lm(more_pop ~ renta_hogar, data = districts %>% filter(tw_count > 0 & bt_count > 0)))
ggplot(municipalities %>% filter(bt_count > 0 & bt_count < 1500)) + geom_point(aes(more_tweets, more_pop)) + geom_smooth(aes(more_tweets, more_pop), method = 'lm')
ggplot(municipalities %>% filter(bt_count > 0)) + geom_point(aes(more_tweets, more_pop)) + geom_smooth(aes(more_tweets, more_pop), method = 'lm')
summary(municipalities$more_pop)
sd(municipalities$more_pop)
sd(municipalities$more_pop, na.rm = T)
sd(municipalities$more_tweets, na.rm = T)
ggplot(municipalities %>% filter(bt_count > 0 & more_tweets > -.02 & more_tweets < .02)) + geom_point(aes(more_tweets, more_pop)) + geom_smooth(aes(more_tweets, more_pop), method = 'lm')
municipalities$suburbs <- municipalities$more_pop - municipalities$more_tweets
View(municipalities)
municipalities %>% arrange(suburbs)
municipalities %>% arrange(suburbs) %>% select(NMUN,suburbs)
municipalities %>% arrange(suburbs) %>% select(NMUN,suburbs,tw_count)
municipalities %>% arrange(desc(suburbs)) %>% select(NMUN,suburbs,tw_count)
# KBO Fancy Stats
source("~/Google Drive/KBO/2020elo.R")
serve_site()
to_update <- c("~/kbofancystats/content/elo2020.Rmd",
"~/kbofancystats/content/elohistory.Rmd",
"~/kbofancystats/content/elo.Rmd",
"~/kbofancystats/content/playoffs.Rmd")
for (i in to_update){
temp <- read_file(i)
write_file(temp,i)
}
source("~/Google Drive/Futbol/c19update.R")
source("~/Google Drive/Futbol/c19update.R")
source("~/Google Drive/KBO/2020stats.R")
suppressMessages(library(tidyverse))
suppressMessages(library(rvest))
suppressMessages(library(blogdown))
suppressMessages(library(rmarkdown))
suppressMessages(library(scales))
options(dplyr.summarise.inform=F)
## Start Site
setwd("~/kbofancystats")
serve_site()
build_site()
1+1
suppressMessages(library(tidyverse))
suppressMessages(library(rvest))
suppressMessages(library(blogdown))
suppressMessages(library(rmarkdown))
suppressMessages(library(scales))
options(dplyr.summarise.inform=F)
## Start Site
setwd("~/kbofancystats")
serve_site()
source("~/Google Drive/KBO/2020stats.R")
setwd("~/kbofancystats")
serve_site()
suppressMessages(library(tidyverse))
suppressMessages(library(rvest))
suppressMessages(library(blogdown))
suppressMessages(library(rmarkdown))
suppressMessages(library(scales))
options(dplyr.summarise.inform=F)
## Start Site
setwd("~/kbofancystats")
serve_site()
source("~/Google Drive/Futbol/c19update.R")
source("~/Google Drive/Futbol/c19update.R")
remotes::install_github('rstudio/blogdown')
source("~/Google Drive/Futbol/c19update.R")
setwd("~/futstatcat")
serve_site()
library(knitr)
source("~/Google Drive/Futbol/c19update.R")
stop_server()
