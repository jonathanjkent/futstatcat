sims <- data.frame(predictions, sim.number = rep(1:n.sim, each = nrow(predictions)))
sims$random <- runif((nrow(sims)),0,1)
sims <- mutate(sims, team1.points = ifelse(random < p1, 3,
ifelse(random > (1-p2), 0, 1)))
sims <- mutate(sims, team2.points = ifelse(team1.points == 0, 3,
ifelse(team1.points == 3, 0, 1)))
# Add in known results
sim.seasons <- sims %>% select(team1,team2,sim.number,team1.points,team2.points)
sim.seasons$team1.score <- sim.seasons$team1.points/2
sim.seasons$team2.score <- sim.seasons$team2.points/2
sim.seasons <- rbind(sim.seasons,results.for.sims)
}
if (nrow(schedule) == 0){sim.seasons <- results.for.sims}
# Add in opposite leg (home/away) for each matchup
sim.seasons$matchup <- paste0(sim.seasons$team1,sim.seasons$team2,sim.seasons$sim.number)
legs <- sim.seasons
legs$matchup <- paste0(sim.seasons$team2,sim.seasons$team1,sim.seasons$sim.number)
legs <- legs %>% select(-team1,-team2,-sim.number)
names(legs) <- c("team2.points.leg","team1.points.leg","team2.score.leg","team1.score.leg","matchup")
sim.seasons <- sim.seasons %>% left_join(legs, by = "matchup")
# Tally matchup points and goal differential
sim.seasons$team1.matchup.points <- sim.seasons$team1.points + sim.seasons$team1.points.leg
sim.seasons$team1.matchup.gd <- sim.seasons$team1.score + sim.seasons$team1.score.leg - sim.seasons$team2.score - sim.seasons$team2.score.leg
# Matchups as dataframe
matchups <- sim.seasons %>% select(matchup,team1.matchup.points,team1.matchup.gd)
# Create table for each simulated season
sim.tables <- sim.seasons %>% group_by(team1,sim.number) %>% summarize(points = sum(team1.matchup.points)) %>% arrange(desc(points)) %>% arrange(sim.number)
# Create first and second tiebreakers
sim.tables$tie.team <- c(rep(NA, 1), as.character(sim.tables$team1))[1 : length(sim.tables$team1)]
sim.tables$tie.points <- c(rep(NA, 1), sim.tables$points)[1 : length(sim.tables$points)]
sim.tables$matchup <- paste0(sim.tables$team1,sim.tables$tie.team,sim.tables$sim.number)
sim.tables <- sim.tables %>% left_join(matchups, by = "matchup")
sim.tables$tiebreak1 <- ifelse(sim.tables$points == sim.tables$tie.points, sim.tables$team1.matchup.points, 2)
sim.tables$tiebreak2 <- ifelse(sim.tables$points == sim.tables$tie.points, sim.tables$team1.matchup.gd, 0)
sim.tables$team <- sim.tables$team1
sim.tables <- sim.tables %>% ungroup() %>% select(team,sim.number, points, tiebreak1, tiebreak2)
# Add third tiebreaker (goal differential) and sort
gd <- predict_expg(model, team1=schedule$home, team2=schedule$away, return_df = TRUE)
gd$t1gd <- gd$expg1-gd$expg2
gd$t2gd <- gd$expg2-gd$expg1
results$home.gd <- results$home.score-results$away.score
results$away.gd <- results$away.score-results$home.score
lg.gd <- as_tibble_col(c(as.character(results$home),as.character(results$away),as.character(gd$team1), as.character(gd$team2)),column_name = "team")
lg.gd$gd <- c(as.numeric(results$home.gd),as.numeric(results$away.gd),as.numeric(gd$t1gd), as.numeric(gd$t2gd))
lg.gd <- lg.gd %>% group_by(team) %>% summarize(gd = sum(gd))
sim.tables <- sim.tables %>% left_join(lg.gd, by = "team")
sim.tables <- sim.tables %>% arrange(desc(gd)) %>% arrange(desc(tiebreak2)) %>% arrange(desc(tiebreak1)) %>% arrange(desc(points)) %>% arrange(sim.number)
# Add rank
sim.tables$rank <- rep(1:teams, times = (nrow(sim.tables)/teams))
type1 <- sim.tables %>% filter(rank <= lg.type1) %>%
group_by(team) %>% count() %>% mutate(type1 = (n/n.sim)*100) %>% select(-n) %>% ungroup()
type2 <- sim.tables %>% filter(rank > lg.start2 & rank < lg.type2) %>%
group_by(team) %>% count() %>% mutate(type2 = (n/n.sim)*100) %>% select(-n) %>% ungroup()
type3 <- sim.tables %>% filter(rank > lg.type3) %>%
group_by(team) %>% count() %>% mutate(type3 = (n/n.sim)*100) %>% select(-n) %>% ungroup()
typex <- sim.tables %>% filter(rank == 5 | rank == 6 | rank == 7) %>%
group_by(team) %>% count() %>% mutate(typex = (n/n.sim)*100) %>% select(-n) %>% ungroup()
avgrank <- sim.tables %>% group_by(team) %>% summarize(avgrank = mean(rank)) %>% ungroup()
print("Simulation Complete")
# Create xGols
rate.sked <- data.frame(clublist)
colnames(rate.sked) <- "team"
rate.sked$team2 <- "nobody"
n <- nrow(rate.sked)+1
xgmodel <- model
xgmodel$parameters$attack[n] <- 0
names(xgmodel$parameters$attack[n]) <- c("nobody")
newnames <- names(xgmodel$parameters$attack)
newnames[n] <- "nobody"
names(xgmodel$parameters$attack) <- newnames
xgmodel$parameters$defense[n] <- 0
newnames <- names(xgmodel$parameters$defense)
newnames[n] <- "nobody"
names(xgmodel$parameters$defense) <- newnames
xgmodel$all_teams[n] <- "nobody"
rate.preds <- predict_expg(xgmodel, team1=rate.sked$team, team2=rate.sked$team2, return_df = TRUE)
rate.preds.away <- predict_expg(xgmodel, team1=rate.sked$team2, team2=rate.sked$team, return_df = TRUE)
rate.preds.away$team1 <- rate.preds.away$team2
rate.preds <- rate.preds %>% select(-team2) %>% left_join(rate.preds.away, by = "team1")
rate.preds$expg1 <- (rate.preds$expg1.x + rate.preds$expg2.y)/2
rate.preds$expg2 <- (rate.preds$expg2.x + rate.preds$expg1.y)/2
xgols <- rate.preds %>% select(team1, expg1, expg2) %>% rename(
team = team1,
off.rank = expg1,
def.rank = expg2)
# Create final table
final.table <- sim.tables %>% group_by(team) %>% summarize(proj.points = sum(points/n.sim)) %>% arrange(desc(proj.points))
final.table <- final.table %>% left_join(lg.gd, by = "team")
final.table <- final.table %>% left_join(type1, by = "team")
final.table <- final.table %>% left_join(type2, by = "team")
final.table <- final.table %>% left_join(typex, by = "team")
final.table <- final.table %>% left_join(type3, by = "team")
final.table <- final.table %>% left_join(xgols, by = "team")
final.table <- final.table %>% left_join(avgrank, by = "team")
final.table <- final.table %>% arrange(avgrank) %>% select(-avgrank)
final.table$qualitat <- (final.table$off.rank - final.table$def.rank + 3)*20
final.table[is.na(final.table)] <- 0
# Create trajectories
all.projs <- NA
if (nrow(results > 0)) {
for (i in trajstart:max(results$jornada)){
# Select jornadas
results.temp <- results %>% filter(jornada < (i+1))
results.temp.hist <- histresults %>% filter(jornada < (i+1))
results.other <- results %>% filter(jornada > (i))
results.other <- results.other %>% select(home, away, jornada)
if (nrow(schedule) > 0 & nrow(results.other) > 0){
schedule.temp <- schedule %>% select(-date)
schedule.temp <- rbind(schedule.temp, results.other)
}
if (nrow(schedule) > 0 & nrow(results.other) == 0){
schedule.temp <- schedule %>% select(-date)
}
if (nrow(schedule) == 0){
schedule.temp <- results.other
}
# Model
weights <- weights_dc(results.temp.hist$date, xi=xi.set)
gm_res <- goalmodel(goals1 = results.temp.hist$home.score, goals2 = results.temp.hist$away.score, team1 = results.temp.hist$home, team2=results.temp.hist$away, weights = weights, rs=TRUE)
# Current Table
table <- results.temp
table <- mutate(table, home.points = ifelse(home.score > away.score, 3,
ifelse(home.score == away.score, 1, 0)))
table <- mutate(table, away.points = ifelse(home.score < away.score, 3,
ifelse(home.score == away.score, 1, 0)))
table.home <- table %>% group_by(home) %>%
summarize(points = sum(home.points))
table.away <- table %>% group_by(away) %>%
summarize(points = sum(away.points))
colnames(table.home)[1] <- 'team'
colnames(table.away)[1] <- 'team'
table.all <- rbind(table.home, table.away)
table.all <- table.all %>% group_by(team) %>%
summarize(points = sum(points)) %>% ungroup()
# Predicted Points
if (nrow(schedule.temp)>0){
predictions.temp <- predict_result(gm_res, team1=schedule.temp$home, team2=schedule.temp$away, return_df = TRUE)
predictions.temp$home.points <- (predictions.temp$p1 * 3) + predictions.temp$pd
predictions.temp$away.points <- (predictions.temp$p2 * 3) + predictions.temp$pd
pred.home <- predictions.temp %>% group_by(team1) %>%
summarize(points = sum(home.points))
pred.away <- predictions.temp %>% group_by(team2) %>%
summarize(points = sum(away.points))
colnames(pred.home)[1] <- 'team'
colnames(pred.away)[1] <- 'team'
pred.all <- rbind(pred.home, pred.away)
pred.all <- pred.all %>% group_by(team) %>%
summarize(points = sum(points))
proj <- rbind(pred.all, table.all)
}
if (nrow(schedule.temp) == 0){proj <- table.all}
# Full Projection
proj <- proj %>% group_by(team) %>%
summarize(points = sum(points))
proj$round <- i
proj$league <- lg.code
all.projs <- rbind(all.projs, proj)
status <- percent((i)/(max(results$jornada)))
print(paste0("Trajectories: Jornada ",i," Complete"))
}
all.projs <- all.projs[complete.cases(all.projs), ]
}
# Add jornada back to predictions, scale
if (nrow(schedule) > 0){
games$key <- paste0(games$home, games$away)
predictions$key <- paste0(predictions$team1, predictions$team2)
predictions <- predictions %>% left_join(games, by = "key") %>% select(jornada, team1, p1, pd, p2, team2)
predictions$p1 <- predictions$p1*100
predictions$pd <- predictions$pd*100
predictions$p2 <- predictions$p2*100
predictions$league <- lg.code
aa.predictions <- rbind(aa.predictions, predictions)
}
# Add league code
final.table$league <- lg.code
if (lg.code == "primera_catalana"){final.table$league <- paste0(lg.code,"_",lg.group)}
if (lg.sg > 0){final.table$league <- paste0(lg.code,"_",lg.sg)}
# Add to other leagues
aa.final.table <- rbind(aa.final.table, final.table)
aa.all.projs <- rbind(aa.all.projs, all.projs)
aa.final.table <- aa.final.table[2:nrow(aa.final.table),]
aa.predictions <- aa.predictions[2:nrow(aa.predictions),]
aa.all.projs <- aa.all.projs[2:nrow(aa.all.projs),] #Only if re-running trajectorie
aa.final.table
write_csv(aa.final.table, "data_tables.csv")
write_csv(aa.predictions, "data_games.csv")
write_csv(aa.all.projs, "data_trajectories.csv")
# Write CSVs
write_csv(aa.final.table, "data_tables.csv")
write_csv(aa.predictions, "data_games.csv")
write_csv(aa.all.projs, "data_trajectories.csv")
teamnames <- read_csv("~/Google Drive/Futbol/teamlist.csv", col_types = cols())
clubs <- aa.final.table %>% select(team, league)
clubs <- clubs %>% left_join(teamnames, by = "team")
lgs <- leagues
colnames(lgs)[2] <- "league"
colnames(lgs)[1] <- "lg.name"
lgs[4:12,2] <- c("primera_catalana_1", "primera_catalana_2", "primera_catalana_3", "primera_catalana_4",
"primera_division_b_femenina_1","segundab_2","segundab_3","tercera_4","tercera_5")
clubs <- clubs %>% left_join(lgs, by = "league")
clubs
for (i in 1:nrow(clubs)){
club <- as.character(clubs[i,1])
lg.code <- as.character(clubs[i,2])
lg.name <- as.character(clubs[i,5])
club.name <- as.character(clubs[i,4])
type1 <- as.numeric(clubs[i,7])
type2 <- as.numeric(clubs[i,8])
type3 <- as.numeric(clubs[i,9])
name1 <- as.character(clubs[i,10])
name2 <- as.character(clubs[i,11])
dashes <- '---'
br <- '<br>'
start <- '```{r echo=F,warning=FALSE,message=FALSE}'
end <- "```"
l1 <- 'date: "2020-06-17"'
l2 <- paste0('title: "', club.name, '"')
l3 <- paste0("subtitle: '", lg.name,"'")
l4 <- paste0("summary: '", lg.name,"'")
l5 <- '### Trajectòria'
start2 <- "```{r fig.width=8, fig.height=5, echo=F,warning=FALSE,message=FALSE}"
l6 <- 'suppressMessages(library(dplyr))'
l7 <- 'suppressMessages(library(ggplot2))'
l8 <- paste0("d <- read.csv('~/Google Drive/Futbol/data_trajectories.csv') %>% filter(team == '",club,"')")
l9 <- paste0("h <- read.csv('~/Google Drive/Futbol/data_tables.csv') %>% filter(league == '",lg.code,"')")
l10a <- paste0("type1 <- as.numeric(h[",type1,",2] + h[",(type1+1),",2])/2")
l10b <- paste0("type2 <- as.numeric(h[",type2,",2] + h[",(type2-1),",2])/2")
l10c <- paste0("type3 <- as.numeric(h[",type3,",2] + h[",(type3+1),",2])/2")
l11 <- paste0("p <- ggplot(data=d) + geom_line(aes(round,points), size = 1.5, color = 'blue') + geom_hline(aes(yintercept=type1), linetype='dashed', color='#5c5c5c') + annotate('text',0,type1,label = '",name1,"', vjust = -.5, hjust = 'left', color='#5c5c5c') + geom_hline(aes(yintercept=type2), linetype='dashed', color='#5c5c5c') + annotate('text',0,type2,label = '",name2,"', vjust = -.5, hjust = 'left', color='#5c5c5c') + geom_hline(aes(yintercept=type3), linetype='dashed', color='#5c5c5c') + annotate('text',0,type3,label = 'Descens', vjust = -.5, hjust = 'left', color='#5c5c5c')")
l11alt <- paste0("p <- ggplot(data=d) + geom_line(aes(round,points), size = 1.5, color = 'blue') + geom_hline(aes(yintercept=type1), linetype='dashed', color='#5c5c5c') + annotate('text',0,type1,label = '",name1,"', vjust = -.5, hjust = 'left', color='#5c5c5c')")
l11alt2 <- paste0("p <- ggplot(data=d) + geom_line(aes(round,points), size = 1.5, color = 'blue') + geom_hline(aes(yintercept=type1), linetype='dashed', color='#5c5c5c') + annotate('text',0,type1,label = '",name1,"', vjust = -.5, hjust = 'left', color='#5c5c5c') + geom_hline(aes(yintercept=type2), linetype='dashed', color='#5c5c5c') + annotate('text',0,type2,label = '",name2,"', vjust = -.5, hjust = 'left', color='#5c5c5c')")
l12 <- 'if (nrow(d)>0){p + theme_minimal() + labs(x = "Jornada", y = "Punts Projectats")}'
space <- " "
l15 <- '### Pròxims partits'
l16 <- 'suppressMessages(library(kableExtra))'
l17 <- 'teamnames <- read.csv("~/Google Drive/Futbol/teamlist.csv") %>% select(-fullname)'
l18 <- 'games <- read.csv("~/Google Drive/Futbol/data_games.csv")'
l19 <- paste0("games <- games %>% filter(team1 == '",club,"' | team2 == '",club,"')")
l20 <- 'if (nrow(games>0)){names(teamnames) <- c("home", "team1")'
l21 <- 'games <- games %>% left_join(teamnames, by = "team1")'
l22 <- 'names(teamnames) <- c("away", "team2")'
l23 <- 'games <- games %>% left_join(teamnames, by = "team2") %>% select(jornada, home, p1, pd, p2, away)'
l24 <- 'kable(games, digits = 1, align = "c", row.names = FALSE, col.names = c("Jornada", "Equip", "Guanyar", "Empatar", "Guanyar", "Equip")) %>% add_header_above(c("2019-20" = 1, "Local" = 2, "(%)" = 1, "Visitant" = 2)) %>% column_spec(2, bold = T) %>% column_spec(6, bold = T)}'
filename <- iconv(club.name,to="ASCII//TRANSLIT")
filename <- tolower(gsub("[[:punct:]]", "", filename))
filename <- paste0(filename,"-",lg.code,".rmd")
filename <- gsub("[[:space:]]", "-", filename)
setwd("~/futstatcat/content/clubs")
writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l10c,l11,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)
if(any(grepl("cat", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l11alt,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("b_f", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l11alt,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("segundab", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l11alt2,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("tercera", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l11alt2,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("segunda_division_f", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l11alt2,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
}
View(clubs)
teamnames <- read_csv("~/Google Drive/Futbol/teamlist.csv", col_types = cols())
## Team pages
clubs <- aa.final.table %>% select(team, league)
clubs <- clubs %>% left_join(teamnames, by = "team")
lgs <- leagues
colnames(lgs)[2] <- "league"
colnames(lgs)[1] <- "lg.name"
lgs[4:12,2] <- c("primera_catalana_1", "primera_catalana_2", "primera_catalana_3", "primera_catalana_4",
"primera_division_b_femenina_1","segundab_2","segundab_3","tercera_4","tercera_5")
clubs <- clubs %>% left_join(lgs, by = "league")
clubs
for (i in 1:nrow(clubs)){
club <- as.character(clubs[i,1])
lg.code <- as.character(clubs[i,2])
lg.name <- as.character(clubs[i,5])
club.name <- as.character(clubs[i,4])
type1 <- as.numeric(clubs[i,7])
type2 <- as.numeric(clubs[i,8])
type3 <- as.numeric(clubs[i,9])
name1 <- as.character(clubs[i,10])
name2 <- as.character(clubs[i,11])
dashes <- '---'
br <- '<br>'
start <- '```{r echo=F,warning=FALSE,message=FALSE}'
end <- "```"
l1 <- 'date: "2020-06-17"'
l2 <- paste0('title: "', club.name, '"')
l3 <- paste0("subtitle: '", lg.name,"'")
l4 <- paste0("summary: '", lg.name,"'")
l5 <- '### Trajectòria'
start2 <- "```{r fig.width=8, fig.height=5, echo=F,warning=FALSE,message=FALSE}"
l6 <- 'suppressMessages(library(dplyr))'
l7 <- 'suppressMessages(library(ggplot2))'
l8 <- paste0("d <- read.csv('~/Google Drive/Futbol/data_trajectories.csv') %>% filter(team == '",club,"')")
l9 <- paste0("h <- read.csv('~/Google Drive/Futbol/data_tables.csv') %>% filter(league == '",lg.code,"')")
l10a <- paste0("type1 <- as.numeric(h[",type1,",2] + h[",(type1+1),",2])/2")
l10b <- paste0("type2 <- as.numeric(h[",type2,",2] + h[",(type2-1),",2])/2")
l10c <- paste0("type3 <- as.numeric(h[",type3,",2] + h[",(type3+1),",2])/2")
l11 <- paste0("p <- ggplot(data=d) + geom_line(aes(round,points), size = 1.5, color = 'blue') + geom_hline(aes(yintercept=type1), linetype='dashed', color='#5c5c5c') + annotate('text',0,type1,label = '",name1,"', vjust = -.5, hjust = 'left', color='#5c5c5c') + geom_hline(aes(yintercept=type2), linetype='dashed', color='#5c5c5c') + annotate('text',0,type2,label = '",name2,"', vjust = -.5, hjust = 'left', color='#5c5c5c') + geom_hline(aes(yintercept=type3), linetype='dashed', color='#5c5c5c') + annotate('text',0,type3,label = 'Descens', vjust = -.5, hjust = 'left', color='#5c5c5c')")
l11alt <- paste0("p <- ggplot(data=d) + geom_line(aes(round,points), size = 1.5, color = 'blue') + geom_hline(aes(yintercept=type1), linetype='dashed', color='#5c5c5c') + annotate('text',0,type1,label = '",name1,"', vjust = -.5, hjust = 'left', color='#5c5c5c')")
l11alt2 <- paste0("p <- ggplot(data=d) + geom_line(aes(round,points), size = 1.5, color = 'blue') + geom_hline(aes(yintercept=type1), linetype='dashed', color='#5c5c5c') + annotate('text',0,type1,label = '",name1,"', vjust = -.5, hjust = 'left', color='#5c5c5c') + geom_hline(aes(yintercept=type2), linetype='dashed', color='#5c5c5c') + annotate('text',0,type2,label = '",name2,"', vjust = -.5, hjust = 'left', color='#5c5c5c')")
l12 <- 'if (nrow(d)>0){p + theme_minimal() + labs(x = "Jornada", y = "Punts Projectats")}'
space <- " "
l15 <- '### Pròxims partits'
l16 <- 'suppressMessages(library(kableExtra))'
l17 <- 'teamnames <- read.csv("~/Google Drive/Futbol/teamlist.csv") %>% select(-fullname)'
l18 <- 'games <- read.csv("~/Google Drive/Futbol/data_games.csv")'
l19 <- paste0("games <- games %>% filter(team1 == '",club,"' | team2 == '",club,"')")
l20 <- 'if (nrow(games>0)){names(teamnames) <- c("home", "team1")'
l21 <- 'games <- games %>% left_join(teamnames, by = "team1")'
l22 <- 'names(teamnames) <- c("away", "team2")'
l23 <- 'games <- games %>% left_join(teamnames, by = "team2") %>% select(jornada, home, p1, pd, p2, away)'
l24 <- 'kable(games, digits = 1, align = "c", row.names = FALSE, col.names = c("Jornada", "Equip", "Guanyar", "Empatar", "Guanyar", "Equip")) %>% add_header_above(c("2019-20" = 1, "Local" = 2, "(%)" = 1, "Visitant" = 2)) %>% column_spec(2, bold = T) %>% column_spec(6, bold = T)}'
filename <- iconv(club.name,to="ASCII//TRANSLIT")
filename <- tolower(gsub("[[:punct:]]", "", filename))
filename <- paste0(filename,"-",lg.code,".rmd")
filename <- gsub("[[:space:]]", "-", filename)
setwd("~/futstatcat/content/clubs")
writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l10c,l11,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)
if(any(grepl("cat", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l11alt,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("b_f", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l11alt,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("segundab", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l11alt2,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("tercera", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l11alt2,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
if(any(grepl("segunda_division_f", lg.code))){writeLines(c(dashes,l1,l2,l3,l4,dashes,l5,start2,l6,l7,l8,l9,l10a,l10b,l11alt2,l12,end,space,l15,start,l16,l17,l18,l19,l20,l21,l22,l23,l24,end), filename)}
}
View(aa.final.table)
View(aa.final.table)
suppressMessages(library(dplyr))
suppressMessages(library(kableExtra))
table <- read.csv("~/Google Drive/Futbol/data_tables.csv") %>% filter(league == "segunda_division_femenina")
table <- teamnames %>% left_join(table, by = "team") %>% arrange(desc(proj.points))
table <- table[complete.cases(table),]
table$linkteam <- iconv(table$fullname,to="ASCII//TRANSLIT")
table$linkteam <- tolower(gsub("[[:punct:]]", "", table$linkteam))
table$linkteam <- gsub("[[:space:]]", "-", table$linkteam)
table$team <- paste0("[", table$shortname, "](/clubs/", table$linkteam,"-",table$league,")")
table <- table %>% select(-shortname,-fullname,-league,-typex,-type2,-linkteam)
table
# FutStat.cat
source("~/Google Drive/Futbol/futstat.R")
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Collapse by autonomous community and municipality
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
###
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
install.packages("sf")
library(tidyverse)
library(sf)
library(ggplot2)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Collapse by autonomous community and municipality
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
###
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
library(sf)
install.packages(c("blogdown", "bookdown", "brms", "broom", "callr", "cli", "clipr", "clubSandwich", "coda", "cpp11", "diffobj", "globals", "htmlwidgets", "igraph", "MASS", "mgcv", "nlme", "ps", "psych", "quantreg", "ragg", "Rdpack", "readr", "rlang", "rmarkdown", "rstan", "sandwich", "servr", "sp", "survival", "systemfonts", "tibble", "vdiffr", "xfun"))
install.packages(c("blogdown", "bookdown", "brms", "broom", "callr", "cli", "clipr", "clubSandwich", "coda", "cpp11", "diffobj", "globals", "htmlwidgets", "igraph", "MASS", "mgcv", "nlme", "ps", "psych", "quantreg", "ragg", "Rdpack", "readr", "rlang", "rmarkdown", "rstan", "sandwich", "servr", "sp", "survival", "systemfonts", "tibble", "vdiffr", "xfun"))
install.packages(c("blogdown", "bookdown", "brms", "broom", "callr", "cli", "clipr", "clubSandwich", "coda", "cpp11", "diffobj", "globals", "htmlwidgets", "igraph", "MASS", "mgcv", "nlme", "ps", "psych", "quantreg", "ragg", "Rdpack", "readr", "rlang", "rmarkdown", "rstan", "sandwich", "servr", "sp", "survival", "systemfonts", "tibble", "vdiffr", "xfun"))
install.packages("sf")
library(sf)
remove.packages(sf)
remove.packages("sf")
library(sf)
install.packages("sf")
library(sf)
library(sf)
library(devtools)
install_github("r-spatial/sf")
library(sf)
library(devtools)
install_github("r-spatial/sf")
library(sf)
library(sf)
library(tidyverse)
library(sf)
# Load background track data
bgtracks <- read_csv("~/research/data/exp_raw/tigaserver_app_fix.csv")
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Collapse by autonomous community and municipality
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
###
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
# Load background track data
bgtracks <- readRDS("~/research/data/exp_pro/user_locations_small_cell.rds")
head(bgtracks)
# Randomize location within sampling cell
bgtracks$fake_lon <- bgtracks$masked_lon + runif(nrow(bgtracks), 0, .025)
bgtracks$fake_lat <- bgtracks$masked_lat + runif(nrow(bgtracks), 0, .025)
# Convert points to SF objects
bgtracks <- bgtracks %>% st_as_sf(coords = c("fake_lon", "fake_lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Load districts as SF objects
districts <- st_read("~/research/shapefiles/SECC_CPV_E_20111101_01_R_INE.shp")
tail(bgtracks)
districts <- st_transform(districts, "+proj=longlat +ellps=WGS84 +datum=WGS84")
# Add background track count to district data
districts$bt_count <- lengths(st_intersects(districts, bgtracks))
# Load tweets, add tweet count to district data
tweets <- readRDS("~/research/sfm_export_b4f78871b13d4773a0bcde6cb2c348db.rds")
tweets <- tweets %>% st_as_sf(coords = c("lon", "lat"), crs = "+proj=longlat +ellps=WGS84 +datum=WGS84")
districts$tw_count <- lengths(st_intersects(districts, tweets))
# Background tracks and tweets as proportion
districts$bt_pct <- districts$bt_count/sum(districts$bt_count)
districts$tw_pct <- districts$tw_count/sum(districts$tw_count)
districts$more_tweets <- districts$tw_pct - districts$bt_pct
# Collapse by autonomous community and municipality
communities <- st_make_valid(districts) %>% group_by(NCA) %>% summarise_at(vars(bt_count, tw_count), sum)
communities$bt_pct <- communities$bt_count/sum(communities$bt_count)
communities$tw_pct <- communities$tw_count/sum(communities$tw_count)
communities$more_tweets <- communities$tw_pct - communities$bt_pct
municipalities <- st_make_valid(districts) %>% group_by(NMUN) %>% summarise_at(vars(bt_count, tw_count), sum)
municipalities$bt_pct <- municipalities$bt_count/sum(municipalities$bt_count)
municipalities$tw_pct <- municipalities$tw_count/sum(municipalities$tw_count)
municipalities$more_tweets <- municipalities$tw_pct - municipalities$bt_pct
###
# Load and add income data to district data
income <- read_csv("~/research/incomebybarri.csv")
income$renta_persona <- as.numeric(income$renta_persona)
income$renta_hogar <- as.numeric(income$renta_hogar)
income <- income %>% separate(area, c("CUSEC", "NMUN2"))
districts <- districts %>% left_join(income, by = "CUSEC")
communities
View(communities)
